<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>NLP - 标签 - Cyan&#39;s Notebook</title>
    <link>/tags/nlp/</link>
    <description>NLP - 标签 - Cyan&#39;s Notebook</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Wed, 06 Apr 2022 21:08:15 &#43;0800</lastBuildDate><atom:link href="/tags/nlp/" rel="self" type="application/rss+xml" /><item>
  <title>BERT</title>
  <link>/posts/bert/</link>
  <pubDate>Wed, 06 Apr 2022 21:08:15 &#43;0800</pubDate>
  <author>Cyan</author>
  <guid>/posts/bert/</guid>
  <description><![CDATA[前言 研究BERT（无果），记录些好的参考（减轻浏览器收藏夹的压力……）
参考 论文解读:BERT模型及fine-tuning - 知乎 (zhihu.com)
LeeMeng - 進擊的 BERT：NLP 界的巨人之力與遷移學習
google-research/bert: TensorFlow code and pre-trained models for BERT (github.com)
LeeMeng - 淺談神經機器翻譯 &amp; 用 Transformer 與 TensorFlow 2 英翻中]]></description>
</item>
</channel>
</rss>
