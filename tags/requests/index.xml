<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>requests - 标签 - Cyan&#39;s Notebook</title>
    <link>/tags/requests/</link>
    <description>requests - 标签 - Cyan&#39;s Notebook</description>
    <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Tue, 14 Sep 2021 08:26:00 &#43;0800</lastBuildDate><atom:link href="/tags/requests/" rel="self" type="application/rss+xml" /><item>
  <title>Python Requests库代理</title>
  <link>/posts/requestsproxy/</link>
  <pubDate>Tue, 14 Sep 2021 08:26:00 &#43;0800</pubDate>
  <author>Cyan</author>
  <guid>/posts/requestsproxy/</guid>
  <description><![CDATA[ 并不是关于IP池，而是用于本地挂代理爬需要翻墙的数据
问题的发现与解决 在requests库较新版本，通过挂系统代理来爬取HTTPS会报SSL错误。
查了很多资料，大部分是 更换使用的包到urllib、降低requests库版本……
解决不了问题，就解决发现问题的东西吗(ﾟДﾟ*)ﾉ
然后自己思考了一会，想起来爬虫有个IP池的操作，本质上也是使用别人的代理，那么，把代理指向本地呢——问题完美解决
1 2 3 4 5 6 7 8 9 10 import requests headers = { &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36 Edg/92.0.902.78&#39; } sys_proxies = {&#39;https&#39;: &#39;http://127.0.0.1:7890&#39;, &#39;http&#39;: &#39;http://127.0.0.1:7890&#39;}	# 指向本地代理 response = requests.get(json_url(tag, page), headers=headers, proxies=sys_proxies) # 配置代理 ]]></description>
</item>
</channel>
</rss>
