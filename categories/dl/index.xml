<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DL on Cyan</title>
    <link>https://cyan-ripple.github.io/categories/dl/</link>
    <description>Recent content in DL on Cyan</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 21 May 2022 19:21:32 +0800</lastBuildDate><atom:link href="https://cyan-ripple.github.io/categories/dl/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CUDA、CUDNN</title>
      <link>https://cyan-ripple.github.io/post/cuda_cudnn/</link>
      <pubDate>Sat, 21 May 2022 19:21:32 +0800</pubDate>
      
      <guid>https://cyan-ripple.github.io/post/cuda_cudnn/</guid>
      <description>CUDA与CUDNN CUDA CUDA（Compute Unified Device Architecture），是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。
CUDA_百度百科 (baidu.com)
CUDNN NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。NVIDIA cuDNN可以集成到更高级别的机器学习框架中，如谷歌的Tensorflow、加州大学伯克利分校的流行caffe软件。简单的插入式设计可以让开发人员专注于设计和实现神经网络模型，而不是简单调整性能，同时还可以在GPU上实现高性能现代并行计算。
参考（强烈推荐）：CUDA与cuDNN - 简书 (jianshu.com)
NVIDIA的驱动与CUDA版本 在第一次装的时候，满脑子？？？
 NVDIA驱动安装的有个CUDA了，版本和需要的不对怎么办，难道重装驱动吗？ 需要多个CUDA怎么办？  驱动版本与CUDA版本 随驱动安装的叫做driver版本，自己后续安装的叫做runtime版本，可以随意安装多个版本的CUDA，但是保证driver版本号&amp;gt;=runtime版本号
多版本共存 程序在调用CUDA的时候一般是利用path（或者说是windows环境变量）去加载dll等，保证每个版本的文件完整，并且在path中能够搜索到即可（windows也就是配置好环境变量）。
安装 首先要确定需要安装的版本。tensorflow可以在从源代码构建 | TensorFlow (google.cn)查看
手动安装  Linux建议直接CONDA安装
 下载地址 CUDA：CUDA Toolkit Archive | NVIDIA Developer
CUDNN：NVIDIA cuDNN | NVIDIA Developer
安装  建议看下面的博客，讲的很好
 cuda安装教程+cudnn安装教程_sinat_23619409的博客-CSDN博客_cuda安装
使用CONDA安装 CUDA
conda install cudatoolkit=&amp;lt;版本&amp;gt; cuDNN
conda install cudnn=&amp;lt;版本&amp;gt; </description>
    </item>
    
    <item>
      <title>Optimizer</title>
      <link>https://cyan-ripple.github.io/post/optimizer/</link>
      <pubDate>Tue, 05 Apr 2022 22:43:07 +0800</pubDate>
      
      <guid>https://cyan-ripple.github.io/post/optimizer/</guid>
      <description>前言 参考的资料和自己在进行炼丹（姑且这么称作）的时候，经常使用的是Adam，在尝试了learning_rate, schedule等方法（无果，大概…）后，突然想到要去了解一下其中的原理。
资料 一个框架看懂优化算法之异同 SGD/AdaGrad/Adam - 知乎 (zhihu.com)
Adam那么棒，为什么还对SGD念念不忘 (2)—— Adam的两宗罪 - 知乎 (zhihu.com)
Adam那么棒，为什么还对SGD念念不忘 (3)—— 优化算法的选择与使用策略 - 知乎 (zhihu.com)
综述 Adam自带优化，会调整learning_rate（所以自己再用schedule, 微调learning_rate貌似没啥用了……
大神都用SGD手调参数</description>
    </item>
    
    <item>
      <title>tensorflow1、2设置不占满显存</title>
      <link>https://cyan-ripple.github.io/post/tf_mem/</link>
      <pubDate>Thu, 16 Sep 2021 18:46:00 +0800</pubDate>
      
      <guid>https://cyan-ripple.github.io/post/tf_mem/</guid>
      <description>tensorflow的默认调度策略是吃满显存，如果我们模型较小、显存较大、占用率不足40%（自己估计的）时，是可以利用GPU同时训练两个模型的。
tensorflow 1 config = tf.ConfigProto() config.gpu_options.allow_growth = True sess = tf.Session(config=config) tensorflow 2 gpus = tf.config.list_physical_devices(device_type=&amp;#39;GPU&amp;#39;) for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True) </description>
    </item>
    
  </channel>
</rss>
